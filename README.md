# CLI-клиент для LLM

Простой CLI-скрипт для отправки запросов в LLM через LiteLLM Proxy.

## Установка

1. Установите зависимости:
```bash
pip3 install -r requirements.txt
```

2. Установите переменную окружения с API-ключом:
```bash
export OPENAI_API_KEY="ваш_api_ключ"
```

## Использование

Запустите скрипт:
```bash
python3 llm_client.py
```

Введите ваше сообщение и нажмите Enter. Для выхода введите `exit`.

## Переменные окружения

- `OPENAI_API_KEY` — обязательно. API-ключ для аутентификации
- `OPENAI_BASE_URL` — опционально. URL LiteLLM Proxy (по умолчанию: https://llmlite.ailab-copilot-prod.corp.tander.ru)

## Пример

```
==================================================
CLI-клиент для LLM
==================================================
Введите ваше сообщение (или 'exit' для выхода)
--------------------------------------------------

Вы: Привет, напиши короткое стихотворение

LLM: Привет! Вот короткое стихотворение для вас:
...
